# https://towardsdatascience.com/self-attention-in-computer-vision-2782727021f6
# https://arxiv.org/pdf/1801.09927.pdf

import argparse
parser = argparse.ArgumentParser()
parser.add_argument('dataset')
parser.add_argument('--epochs', type=int, default=100)
parser.add_argument('--batchsize', type=int, default=8)
parser.add_argument('--tau', type=float, default=0.7)
parser.add_argument('--output')
args = parser.parse_args()

import tensorflow as tf
for g in tf.config.experimental.list_physical_devices('GPU'):
    tf.config.experimental.set_memory_growth(g, True)
import numpy as np
from skimage.measure import label, regionprops
import mydatasets, mymodels, mydatagen

(Xtr, Ytr), tss = getattr(mydatasets, args.dataset)()
g = mydatagen.Gen(Xtr, Ytr, args.batchsize)

# 1. Train global model

ce = tf.keras.losses.SparseCategoricalCrossentropy(True)
acc = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')

global_model = mymodels.vgg19 if Xtr.shape[1] >= 128 else mymodels.classifier
global_model, opt = global_model(Xtr.shape[1:], Ytr.max()+1)
global_model.summary()
global_model.compile(opt, ce, [acc])

global_model.fit(g.flow(), steps_per_epoch=g.steps(),
    epochs=args.epochs, verbose=2, validation_data=tss[-1])

# 2. Masks and bounding boxes

def crop_heatmap(x):
    # the heatmap is generated by reducing channels using the maximum absolute
    h = heatmap_model.predict(x)[0]
    h = np.max(np.abs(h), 2)
    # mask is created by using a threshold on the normalized heatmap
    min_h = np.min(h)
    max_h = np.max(h)
    if min_h == max_h:
        return None
    h = (h - min_h) / (max_h - min_h)
    m = h >= args.tau
    # get bounding box of largest bounding box
    labels = label(m)
    largest = labels == np.argmax(np.bincount(labels.flat)[1:])+1
    row1, col1, row2, col2 = regionprops(largest.astype(int))[0].bbox
    # crop
    return x[:,
        x.shape[1]*row1//h.shape[0]:x.shape[1]*row2//h.shape[0]+1,
        x.shape[2]*col1//h.shape[1]:x.shape[2]*col2//h.shape[1]+1]

# 3. Train the attention branch
# Unlike the paper, we train the concatenation of local and global branch at the same time.

def AttClassifier(X, Y, heatmap_model):
    x = input_crop_shape = tf.keras.layers.Input((None, None, X.shape[3]))
    for filters in [128, 256, 512]:
        x = tf.keras.layers.Conv2D(filters, 3, 2, 'same', activation='relu')(x)

    x = tf.keras.layers.GlobalAveragePooling2D()(x)  # crop/local branch
    h = tf.keras.layers.GlobalAveragePooling2D()(heatmap_model.output)  # global branch

    x = tf.keras.layers.Concatenate()([x, h])
    x = tf.keras.layers.Dense(2048)(x)
    x = tf.keras.layers.Dense(256)(x)
    x = tf.keras.layers.Dense(Y.max()+1)(x)
    return tf.keras.models.Model([heatmap_model.input, input_crop_shape], x)

heatmap = [l for l in global_model.layers if type(l).__name__ == 'MaxPooling2D'][-1]
heatmap_model = tf.keras.models.Model(global_model.input, heatmap.output)
heatmap_model.trainable = False

local_model = AttClassifier(Xtr, Ytr, heatmap_model)

def gen(X, Y):
    t = mydatagen.Transform()
    while True:
        ix = np.random.choice(len(X), len(X), False)
        sum_crop_size = np.zeros((2,))
        for i in ix:
            X_ = t.each(X[i])[np.newaxis]
            X_crop = crop_heatmap(X_)
            if X_crop is None or X_crop.shape[1] == 0 or X_crop.shape[2] == 0:
                continue  # ignore crop of size zero
            sum_crop_size += X_crop.shape[1:3]
            yield [X_, X_crop], Y[i:i+1]
        print('Average crop:', sum_crop_size/len(X))

class ResultsCb(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        for i, (Xts, Yts) in enumerate([(Xtr, Ytr)] + tss):
            scores = local_model.evaluate(gen(Xts, Yts), verbose=0, steps=len(Xts))
            print(f'score {i}:', scores)


local_model.compile('adam', ce, [acc])
local_model.fit(
    gen(Xtr, Ytr), steps_per_epoch=len(Xtr), epochs=args.epochs, verbose=2,
    validation_data=gen(*tss[-1]), validation_steps=len(tss[-1][0]),
    callbacks=[ResultsCb()])

for i, (Xts, Yts) in enumerate([(Xtr, Ytr)] + tss):
    scores = local_model.evaluate(gen(Xts, Yts), verbose=0, steps=len(Xts))
    print(f'score {i}:', scores)
